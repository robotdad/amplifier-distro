# Chat-to-Voice Session Handoff Design

## Clarifying Questions and Answers

*No feature was specified, so the following questions were posed against the project context and answered from first principles.*

---

**Q1: What exactly does "chat-to-voice" mean for the user, and why is it on the roadmap?**

A: A user mid-way through a text chat session (or a CLI conversation) wants to continue that work as a voice conversation — "continue this in voice" — without losing the context of what was discussed. This fulfills the AMPLIFIER_HOME_CONTRACT's explicit cross-interface promise: *"CLI session can be resumed in TUI, voice, or web chat."* Voice is the only direction of this promise not yet implemented. The inverse already works: voice sessions resume in voice.

---

**Q2: Why can't the full chat transcript be injected into the new Realtime session?**

A: Three compounding reasons:
1. **Format mismatch.** Chat transcripts contain markdown, code blocks, raw tool output JSON, and long structured assistant responses. The Realtime voice model cannot usefully narrate these and would produce garbled or overly verbose audio if it tried.
2. **Context budget pressure.** A substantive chat session fills the Realtime API's 128K context budget before the user speaks their first voice query, leaving no room for the actual conversation.
3. **Signal-to-noise.** The voice model needs to answer one question: *"What were we doing and what state are we in?"* A 2-paragraph summary serves this better than 200 raw messages. Quantity of history injected is inversely correlated with how naturally the voice model can continue.

---

**Q3: What is the right context unit to inject for a non-voice session?**

A: Two layers, in priority order:

1. **Handoff summary** (`handoff.md`) — auto-generated by `hooks-handoff` at every significant session milestone. Plain prose: what was worked on, key decisions, current state, what was left open. Written exactly for this scenario. Lives at `~/.amplifier/projects/{project_id}/sessions/{session_id}/handoff.md`. This is the primary context signal.
2. **Recent turns** (last 5–10 user/assistant exchanges) — for immediate conversational coherence, so the voice model knows what was just said. User and assistant text only — no tool calls, no tool outputs, no code/file content.

Explicitly excluded: full transcript, tool call arguments/results, code blocks, structured data, anything longer than one or two sentences per turn after the summary.

---

**Q4: What server-side change is needed to support per-session-type context injection?**

A: The `POST /sessions/{id}/resume` route currently hard-codes voice transcript as `context_to_inject`. It needs to branch on `metadata.json`'s `created_by_app` field — already declared load-bearing in `docs/voice-architecture.md`:

- `created_by_app == "voice"` → current behavior unchanged: voice transcript formatted as `conversation.item` objects
- `created_by_app != "voice"` (chat, CLI, Slack, etc.) → new path: `handoff.md` content + last N turns, formatted as voice-suitable `conversation.item` objects

The `FoundationBackend` has session filesystem access via `session_history.py` utilities. No new infrastructure required — `handoff.md` is already written by the hook system; the resume route just needs to read it.

---

**Q5: What frontend changes are needed, and is there new UI?**

A: Minimal. The existing `SessionPicker` component already renders sessions for resumption and calls `handleResume(sessionId)` when selected. The server response shape (`context_to_inject`, `client_secret`) is identical regardless of source session type — the client code path is **unchanged**. Two targeted additions:

1. **SessionPicker source filter:** Currently lists only voice sessions. Should list all sessions (or filter to "resumable" — any session with a `handoff.md`), labeled by `created_by_app` ("Voice conversation" vs "Chat conversation").
2. **Display label in header:** Once resumed, the session header should indicate "Continued from chat" or similar — derived from the injected context's metadata, not new server state.

---

## Goal

Implement cross-interface session continuity so users can resume a text chat (or CLI) session in the voice app, fulfilling the AMPLIFIER_HOME_CONTRACT's cross-interface promise.

## Background

The AMPLIFIER_HOME_CONTRACT declares: *"Cross-interface — CLI session can be resumed in TUI, voice, or web chat."* The voice app already supports voice-to-voice reconnect: `POST /sessions/{id}/resume` fetches the voice transcript, converts it to OpenAI Realtime `conversation.item` format, and returns it as `context_to_inject`. A new Realtime session is initialized with this history; the Amplifier session is the same — only the Realtime connection is new.

Chat-to-voice is the voice direction of this same promise. The mechanism is identical: resume the same Amplifier session, inject context into a new Realtime session. The challenge is what context to inject — and the answer is **not** the full chat transcript.

The `docs/voice-architecture.md` document (written 2026-02-27) explicitly called out this feature as the north star and pre-decided the discriminator (`created_by_app`), the context source (`handoff.md` + last N turns), and the constraint (NOT the full transcript). This design implements that pre-decision.

## Approach

Extend `resume_session()` on the server to be context-source-aware, branching on `created_by_app`. The client is untouched except for widening the `SessionPicker` filter. No new endpoints, no new models, no new infrastructure — the filesystem already has what we need.

The guiding principle is **minimum viable context injection**: give the voice model enough to continue naturally, no more. Err toward less context; the model can ask the user to elaborate.

## Architecture

```
SessionPicker (widened filter)
    │
    └─ handleResume(sessionId)          [unchanged]
         │
         └─ POST /sessions/{id}/resume
               │
               ├─ read metadata.json → created_by_app
               │
               ├─ [voice] existing path: voice_transcript → conversation.item[]
               │
               └─ [non-voice] new path:
                     ├─ read handoff.md   → summary item
                     └─ read last N turns → recent exchange items
                         │
                         └─ context_to_inject: [summary_item, ...recent_items]
```

Both paths return the same response shape. The Realtime session initialization (`handleResume` → WebRTC setup → `conversation.item.create` injection) is completely unchanged.

## Components

### `resume_session()` — server (`apps/voice/__init__.py`)

The route handler at `POST /sessions/{id}/resume`. Currently calls `backend.resume_session()` and returns `context_to_inject`. Needs two changes:

1. Read `metadata.json` to get `created_by_app` before calling the backend.
2. Delegate to a new `_build_context_for_resume(session_id, project_id, created_by_app)` helper that returns `list[dict]` of `conversation.item`-formatted objects.

The route signature and response shape are unchanged.

### `_build_context_for_resume()` — new helper (same file or `transcript/context.py`)

```python
async def _build_context_for_resume(
    session_id: str,
    project_id: str,
    created_by_app: str,
    recent_turns: int = 8,
) -> list[dict]:
    ...
```

Branches on `created_by_app`:
- `"voice"` → delegates to existing voice transcript conversion (extract and inline the current inline logic)
- anything else → `_build_chat_context(session_id, project_id, recent_turns)`

### `_build_chat_context()` — new helper

Reads two sources from `~/.amplifier/projects/{project_id}/sessions/{session_id}/`:

1. **`handoff.md`** — if present, formats as a single `conversation.item` of type `message`, role `assistant`, with preamble *"Context from prior text session:"* followed by the handoff content.
2. **Session transcript** (last `recent_turns` user+assistant pairs) — reads the session's transcript JSON, extracts the tail of the conversation, filters to `role: user` and `role: assistant` text turns only, formats each as `conversation.item`.

If `handoff.md` is absent (session predates the hook, or hook never ran), falls back to recent turns only with a short synthetic preamble.

Returns a `list[dict]` shaped as OpenAI Realtime `conversation.item` objects ready for `conversation.item.create` injection.

### `SessionPicker` — frontend (`static/index.html`)

Currently filters sessions to only show `created_by_app == "voice"`. Change the filter predicate to include any session that has a `handoff.md` present, or simply remove the filter and show all sessions labeled by source app.

The session list endpoint (`GET /sessions`) already returns `created_by_app` in the session metadata. No backend change required — just update the frontend filter and add an app-type label to the session list item rendering.

## Data Flow

```
1. User opens SessionPicker in voice app
2. Session list shows: voice sessions + chat sessions (labeled)
3. User selects a chat session
4. handleResume(chatSessionId) fires
5. POST /sessions/{chatSessionId}/resume
6. Server reads metadata.json → created_by_app == "chat"
7. Server reads handoff.md → summary text
8. Server reads session transcript → last 8 user/assistant turns
9. Server formats context_to_inject: [handoff_item, turn1, turn2, ..., turn8]
10. Server returns: { client_secret, context_to_inject }
11. Browser starts new WebRTC session (same as voice-to-voice resume)
12. On dc.onopen: session.update (VAD + tools configured)
13. Browser iterates context_to_inject → sends conversation.item.create for each
14. Browser sends response.create (voice model greets, referencing context)
15. Voice model: "Welcome back — last time we were working on X. Where would you like to continue?"
```

## Error Handling

**`handoff.md` absent:** Fall back to recent turns only with a synthetic preamble: `"Resuming a text chat session. Here are the most recent exchanges:"`. Never block the resume over a missing summary.

**Session transcript unreadable or empty:** Return an empty `context_to_inject` array. The voice model starts fresh. Log a warning. Do not error the resume.

**`created_by_app` field missing from metadata (legacy session):** Treat as `"unknown"` → use the non-voice path (recent turns, no handoff summary). Safe default.

**Realtime context injection failure (item create rejected):** Log and skip that item. The model proceeds with partial context. Never block the WebRTC connection over a context injection failure.

**User selects a session with no project on disk:** The existing `resume_session()` error handling covers this — returns 404. `handleResume()` shows the error banner (existing behavior).

## Testing Strategy

**Unit test — `_build_chat_context()`:**
Create a fixture session directory with a `handoff.md` and a mock transcript JSON. Assert the returned list starts with the handoff item (correct preamble text, correct role/type shape), followed by the expected number of turn items, with tool calls excluded.

**Unit test — `_build_context_for_resume()` branching:**
Mock the two sub-functions. Assert `created_by_app == "voice"` routes to the voice path, and `created_by_app == "chat"` routes to the chat path.

**Unit test — absent `handoff.md` fallback:**
Run `_build_chat_context()` against a fixture with no `handoff.md`. Assert the result is non-empty (recent turns), no exception raised.

**Integration test — `POST /sessions/{id}/resume` for a chat session:**
Use TestClient with a seeded session fixture on disk (`created_by_app == "chat"`, handoff.md present). Assert response shape matches: `{ client_secret: ..., context_to_inject: [...] }` and `context_to_inject` is non-empty.

**Manual verification checklist:**
- Select a chat session from SessionPicker → confirm voice model opens with context summary
- Select a session where handoff.md is absent → confirm graceful fallback (no crash, recent turns only)
- Select a voice session → confirm existing behavior unchanged (regression)
- Let voice session hit proactive reconnect → confirm same Amplifier session, context preserved

**Regression:** Existing voice-to-voice resume tests pass unchanged. `created_by_app == "voice"` path is pure refactor (extract to helper, behavior identical).

## Open Questions

- **`recent_turns` count:** 8 is the proposed default. Validate against a real chat session — does 8 turns give sufficient coherence without overwhelming? May need to be configurable per-session or per-`created_by_app`.
- **Transcript format variance:** Different app surfaces write transcripts in slightly different JSON structures. `_build_chat_context()` must normalize across chat, CLI, and Slack transcript formats. Audit the three formats before implementation.
- **SessionPicker filter criteria:** "Has `handoff.md`" vs "any session" vs whitelist of `created_by_app` values. Decision deferred to implementation — start permissive and narrow if the list becomes unwieldy.
- **Voice model instruction:** The system prompt for the voice model doesn't currently tell it to expect injected context and introduce itself accordingly. A one-sentence addition ("If context items are present from a prior session, briefly acknowledge what was being worked on") would significantly improve the opening UX.
